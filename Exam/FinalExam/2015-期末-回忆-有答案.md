# 2015年秋季学期操作系统期末考试题目总结

## 一、简答题 (共20分, 每题5分)

1.  关于CPU特权等级的问题。

    CPU特权等级是一种硬件保护机制，它将处理器操作模式至少分为**内核态**和**用户态**。
    
    *   **内核态 (高特权):** 运行操作系统内核，可以执行所有指令，访问所有硬件资源。
    *   **用户态 (低特权):** 运行应用程序，指令和资源访问受限。
    
    这种分离设计通过**防止用户程序直接执行危险指令**来保护系统稳定。当用户程序需要进行I/O等特权操作时，必须通过**系统调用 (System Call)** 的方式请求内核服务，此时CPU会从用户态切换到内核态，完成操作后再切换回来。

2.  哪些调度方式可能导致饥饿？哪些可能导致优先级反转？

    *   **导致饥饿 (Starvation):**
        *   **严格优先级调度:** 低优先级进程可能永远被高优先级进程抢占。
        *   **最短作业优先 (SJF):** 长作业可能永远被源源不断的新短作业插队。

    *   **导致优先级反转 (Priority Inversion):**
        *   抢占式优先级调度 + 共享资源（如锁）。一个高优先级任务(H)因等待低优先级任务(L)持有的锁而被阻塞。此时，一个中优先级任务(M)抢占了L，导致L迟迟无法释放锁，从而间接阻塞了H。

3.  写时拷贝（Copy-on-Write）与内存映射文件（Memory-Mapped Files）的相似之处。

    两者核心的相似之处在于都应用了**延迟处理 (Lazy Evaluation)** 的思想，并且都依赖**缺页异常 (Page Fault)** 作为核心触发机制。都在虚拟内存中先建立一个"承诺"的映射，而不立即执行昂贵的数据操作（物理复制或文件读取）。

    *   **内存映射文件 (MMF):** 当访问一个未加载的页面时，触发缺页异常，**从磁盘按需调页**。
    *   **写时拷贝 (COW):** 当对一个共享的只读页面进行写入时，触发保护性缺页异常，**按需复制该页**使其私有化。

    两者都体现了虚拟内存的精髓：以页为单位，通过操纵页表实现高效的资源管理。

4.  以打印机输出为例，说明I/O软件（分层）的设计思想。

    I/O软件分层是将复杂的I/O流程分解为独立的层次，每层向上提供服务并隐藏下层细节。以打印为例：

    ```mermaid
    graph TD
        A["应用 (Word)"] --> B["设备无关层 (OS)"];
        B --> C["设备驱动层 (HP驱动)"];
        C --> D["硬件 (打印机)"];
    ```

    1.  **应用层:** 发起打印请求，不关心打印机型号。
    2.  **设备无关的I/O层:** 提供统一接口，并处理通用任务，如打印作业的缓冲和假脱机(Spooling)。
    3.  **设备驱动层:** 将上层的通用请求，翻译成特定打印机能懂的硬件指令（如PCL）。
    4.  **硬件层:** 实际执行指令的物理设备。

    **设计思想的好处:**
    *   **抽象与模块化:** 更换硬件只需更换驱动，上层软件不变。
    *   **统一性:** 不同应用可以使用同样的方式操作不同设备。

## 二、选做题 (二选一, 共10分)

1.  **分析以下轮序代码，指出其问题并提供解决方案。**

    ```assembly
    LOOP: TEST PORT-4
        BEQ READY
        BRANCH LOOP
    READY:
    ```

    **问题分析:**
    上述代码采用了 **"忙等待" (Busy-Waiting)** 或 **轮询 (Polling)** 的方式来检查I/O设备的状态。CPU会陷入一个循环 (`LOOP`)，不断地消耗时钟周期去读取设备端口 `PORT-4` 的状态，直到设备就绪。

    **主要问题:**
    *   **CPU效率低下:** 在等待设备期间，CPU被完全占用，无法执行其他任何有用的计算任务或调度其他进程。这在多任务操作系统中是极大的资源浪费。

    **解决方案:**
    改用 **中断驱动I/O (Interrupt-driven I/O)**。

    **改进流程:**
    1.  **发起请求:** CPU向设备发起一个I/O请求。
    2.  **阻塞/调度:** CPU不等待，而是将当前进程置于等待状态，并调度另一个就绪进程来执行。
    3.  **设备通知:** 当I/O设备完成操作时，它会向CPU发送一个 **中断信号**。
    4.  **中断处理:** CPU接收到中断后，暂停当前任务，跳转到该设备的 **中断服务程序 (ISR)**。
    5.  **处理数据:** ISR负责处理I/O，然后清除中断信号。
    6.  **恢复执行:** ISR执行完毕后，原先等待I/O的进程被唤醒，CPU恢复执行被中断的任务。

    **优点:**
    *   **解放CPU:** CPU无需空等，系统整体效率和吞吐量大大提高。
    *   **并发性:** 实现了CPU与I/O设备的真正并行工作。

2.  简述远程过程调用（RPC）是如何及为何要生成存根（stub）。**实验班问题，不考。**

## 三、存储管理 (共30分)

1. 简述在自选的内存组织方式下，系统解析一个内存地址时的软件和硬件行为。

   以现代操作系统中最核心的 **分页式虚拟存储 (Paging Virtual Memory)** 为例，解析一个内存地址（逻辑地址）涉及硬件和软件的协同工作。

   **1. 硬件行为 (MMU + TLB)**

   当CPU执行一条指令需要访问内存时，它发出的是一个 **逻辑地址 (Virtual Address)**。接下来的处理由CPU内的 **内存管理单元 (MMU)** 主导：

   *   **a. 查询快表 (TLB):** MMU首先从逻辑地址中提取出 **页号 (VPN)**，然后去查询 **TLB (Translation Lookaside Buffer)**。TLB是一个页表项的高速缓存。
       *   **TLB 命中 (Hit):** 如果在TLB中找到了对应的页号，MMU会立即获得其映射的 **物理页框号 (PFN)**。这是最快的情况。
       *   **TLB 未命中 (Miss):** 如果TLB中没有该页号的缓存，MMU就需要执行下一步。

   *   **b. 遍历页表 (Page Table Walk):**
       *   MMU会根据 **页表基址寄存器 (如CR3)** 指向的内存地址，在物理内存中查找 **页表 (Page Table)**。
       *   MMU使用页号作为索引，在页表中找到对应的 **页表项 (PTE)**。在多级页表结构中，这可能需要多次访问内存。
       *   **PTE有效 (Present Bit = 1):** 如果PTE表明该页在物理内存中，MMU会取出物理页框号，并 **将这个映射关系缓存到TLB中**，以备后续快速查找。
       *   **PTE无效 (Present Bit = 0 或权限不足):** 如果PTE表明该页不在内存，或当前操作违反了权限（如对只读页进行写操作），硬件无法自行处理，它会触发一个 **缺页异常 (Page Fault)**，并将控制权交给操作系统内核。

   *   **c. 形成物理地址:**
       *   一旦获得了物理页框号(PFN)，MMU会将其与逻辑地址中的 **页内偏移 (Offset)** 拼接起来，形成最终的 **物理地址 (Physical Address)**，然后通过总线访问该地址。

   **2. 软件行为 (操作系统缺页异常处理)**

   当硬件触发缺页异常后，CPU会切换到 **内核态**，并跳转执行操作系统预设的 **缺页异常处理程序 (Page Fault Handler)**：

   *   **a. 分析异常:** 内核首先分析异常原因。
       *   如果是 **非法访问** (如权限错误)，内核会向该进程发送一个信号 (如 `SIGSEGV`)，通常导致进程被终止。
       *   如果是 **页面确实不在内存中**，则进入下一步。

   *   **b. 调入页面:**
       *   内核在磁盘的交换空间 (Swap Space) 或内存映射文件中找到该页面。
       *   在物理内存中寻找一个 **空闲页框**。若没有空闲页框，则执行 **页面置换算法 (如LRU, Clock)** 来选择一个"牺牲"页框。
       *   如果牺牲页框是"脏"的 (Dirty Bit = 1)，即被修改过，必须先将其内容 **写回磁盘**。
       *   内核发起I/O请求，将所需的页面从磁盘 **读入** 到选定的物理页框中。

   *   **c. 更新页表并返回:**
       *   页面从磁盘加载完成后，内核会 **更新页表项(PTE)**，填入新的物理页框号，并将有效位置为1。
       *   内核处理完成，返回到用户态。硬件会 **重新执行** 之前导致异常的指令。

   **总结:** 硬件(MMU)负责快速的、常规的地址转换；当硬件无法处理时 (即缺页)，它就"求助"于软件(操作系统)来处理复杂的加载和替换逻辑。这个过程完美体现了软硬件协同工作的设计思想。

2. 解释这张图中的每个箭头（约10个），并说明该图反映了何种设计思想。

   <img src="./2015-期末-回忆-有答案.assets/CleanShot 2025-06-08 at 00.04.45@2x.png" alt="CleanShot 2025-06-08 at 00.04.45@2x" style="zoom:30%;" />

    1.  **从 `空闲页面链表` 指向 `进程的工作集`:**
        *   **事件:** **分配新物理页框**。当进程需要一个新的物理内存页 (例如，堆栈增长、堆分配、加载数据) 并且无法通过其他方式 (如软缺页) 满足时，操作系统会从 `空闲页面链表` 中取出一个页框分配给该进程，并将其加入进程的 `工作集`。

    2.  **从 `零初始化页面链表` 指向 `进程的工作集` (由 `需求零缺页异常` 触发):**
        *   **事件:** **分配零初始化页面**。当进程发生 `需求零缺页异常` (Demand Zero Page Fault) ，即需要一个内容保证为全零的新页面时 (例如，分配 BSS 段内存或某些匿名映射) ，操作系统优先从 `零初始化页面链表` 中取出一个预先清零的页框分配给进程。

    3.  **从 `后备页面链表` 指向 `进程的工作集` (由 `"软"缺页异常` 触发):**
        *   **事件:** **软缺页异常处理 (页面回收)**。当进程访问一个最近被从其 `工作集` 中移除但尚未被重新分配的页面 (该页面位于 `后备页面链表`) 时，会发生 `"软"缺页异常` (Soft Page Fault) 。操作系统可以快速地将该页面重新移回进程的 `工作集`，无需从磁盘读取，成本很低。

    4.  **从 `进程的工作集` 指向 `修改页面链表` (标有 `工作集置换`):**
        *   **事件:** **置换脏页面**。当发生 `工作集置换` (Working Set Replacement，通常由内存压力或工作集管理策略触发) 时，如果被选中的牺牲页面是**已被修改过的脏页面**，则它会被移动到 `修改页面链表`。这些页面必须先被写回磁盘才能被重用。

    5.  **从 `进程的工作集` 指向 `后备页面链表` (标有 `工作集置换`):**
        *   **事件:** **置换干净页面**。当发生 `工作集置换` 时，如果被选中的牺牲页面是**未被修改过的干净页面**，则它可以被直接移动到 `后备页面链表`。因为其内容与磁盘副本一致，无需写回，可以快速被回收或重用。

    6.  **从 `修改页面链表` 经过 `已修改页面写出线程` 指向 `后备页面链表`:**
        *   **事件:** **脏页面写回完成**。后台的 `已修改页面写出线程` (Modified Page Writer Thread) 会扫描 `修改页面链表`，将脏页的内容异步写回磁盘。一旦写操作完成，该页面就变成了干净页面，并被移动到 `后备页面链表`，准备被重用。

    7.  **从 `后备页面链表` 指向 `空闲页面链表`:**
        *   **事件:** **重用后备页面**。如果 `后备页面链表` 中的页面在一段时间内没有被任何进程通过软缺页回收，操作系统会认为它不再活跃，将其移动到 `空闲页面链表`，使其可用于满足新的页面分配请求。此时页面与原进程的关联断开。

    8.  **从 `空闲页面链表` 经过 `零初始化页面线程` 指向 `零初始化页面链表`:**
        *   **事件:** **后台页面清零**。一个低优先级的内核线程 (`零初始化页面线程`) 会在系统空闲时从 `空闲页面链表` 中取出页面，将其内容填充为零，然后放入 `零初始化页面链表`。这样可以加快后续 `需求零缺页异常` 的处理速度。

    9.  **从 `修改页面链表` 指向 `进程的工作集`:**
        *   **事件:** **脏页面重新激活**。当进程再次访问一个已被移至 `修改页面链表` 但尚未被写回磁盘的页面时，操作系统可以直接将该页面移回 `进程的工作集`，避免了不必要的磁盘写入操作。这是一种优化，可以在页面仍然被频繁访问的情况下减少 I/O 开销。

    10. **从 `进程的工作集` 指向 `后备页面链表`:**
        *   **事件:** **页面老化或主动释放**。除了工作集置换外，还有其他情况会导致页面从工作集移动到后备页面链表：
            1. **页面老化**：某些操作系统会定期扫描进程的工作集，将一段时间内未被访问的页面 (通过检查访问位) 移至后备页面链表，即使没有内存压力。
            2. **进程主动释放**：当进程通过系统调用 (如 `madvise(MADV_DONTNEED)` 或 `munmap()`) 显式释放某些内存区域时，相应的干净页面会被移动到后备页面链表。
            3. **进程挂起**：当进程被挂起 (swapped out) 时，其工作集中的干净页面可能被移动到后备页面链表，以便在进程恢复运行时能够快速恢复。

3. 解释这张图所体现的设计思想。

   <img src="./2015-期末-回忆-有答案.assets/CleanShot 2025-06-08 at 00.05.08@2x.png" alt="CleanShot 2025-06-08 at 00.05.08@2x" style="zoom:30%;" />

   这张图主要体现了现代操作系统内存管理的三个核心设计思想：

   1.  **虚拟内存 (Virtual Memory):**
       *   **思想:** 为每个进程提供一个巨大、私有的虚拟地址空间，使其看起来像独占了全部内存。它将程序的逻辑地址与物理内存的物理地址分离，并使用磁盘作为后备存储。
       *   **图中体现:** "虚拟内存"框内的页面数量远多于"物理内存"框，且部分页面需要从"磁盘"加载，这展示了虚拟内存突破物理内存限制的核心特征。

   2.  **请求调页 (Demand Paging):**
       *   **思想:** 这是实现虚拟内存的常用策略。系统不会在程序启动时就加载所有页面，而是在页面被实际访问时，通过缺页异常（Page Fault）机制，才从磁盘"按需"调入物理内存。
       *   **图中体现:** 从"磁盘"指向"虚拟内存"的箭头，以及"虚拟内存"到"物理内存"的映射关系，暗示了页面是在需要时才从后备存储（磁盘）加载到物理内存中的。

   3.  **工作集模型 (Working Set Model):**
       *   **思想:** 该模型基于程序的"局部性原理"，即进程在任何一小段时间内，只会访问其地址空间中的一小部分页面。这个活跃的页面集合被称为"工作集"。操作系统致力于将一个进程的完整工作集保留在物理内存中，以实现高效运行并避免频繁的缺页中断（颠簸）。
       *   **图中体现:** 在"物理内存"中，一部分页面被明确圈出并标记为"工作集"，这直观地表达了操作系统会重点管理这部分当前最活跃的内存页面，以保证进程性能。

   总结来说，该图描绘了系统如何通过**虚拟内存**提供大空间抽象，利用**请求调页**实现懒加载，并依据**工作集模型**来优化物理内存的分配和置换策略，最终目标是在有限的物理内存上高效地运行多个进程。

## 四、存储系统 (共20分)

1.  **说明Unix文件系统中不同功能区块的名称及其作用。**

    一个典型的Unix文件系统分区主要包含以下几个功能区块：
    *   **引导块 (Boot Block):** 位于分区的起始位置，包含引导加载程序，用于启动操作系统。
    *   **超级块 (Superblock):** 存储整个文件系统的"全局"元数据，如块大小、i-node总数、数据块总数、空闲块数量等。是文件系统的心脏。
    *   **空闲空间管理区:** 记录哪些磁盘块是空闲的。常见实现有**位图 (Bitmap)**或**空闲块链表**（经典Unix使用**成组链接法**）。
    *   **i-node区 (i-node Area):** 集中存放所有文件的i-node（索引节点）。每个i-node包含了除文件名外的所有文件属性（权限、大小、所有者、时间戳）和指向数据块的指针。
    *   **数据区 (Data Area):** 占据分区绝大部分空间，用于存放所有文件的实际内容以及目录文件的内容。

2.  **绘制一个与Unix文件系统相关的结构图。**

    该图展示了Unix文件系统中，目录、i-node与数据块之间的核心关联：

    ```mermaid
    graph TD
        subgraph "目录文件 (Directory File)"
            DirEntry1["目录项<br>('report.docx', inode=789)"]
            DirEntry2["目录项<br>('images', inode=456)"]
        end

        subgraph "I-node区 (I-node Table)"
            Inode_File["<b>I-node 789</b><br>类型: 文件<br>大小: 15KB<br>权限: rw-r--r--<br>...<br><b>数据块指针列表</b>"]
            Inode_Dir["<b>I-node 456</b><br>类型: 目录<br>权限: rwxr-xr-x<br>...<br><b>数据块指针列表</b>"]
        end

        subgraph "数据区 (Data Blocks)"
            DataBlocks_File["文件 'report.docx' 的数据块"]
            DataBlocks_Dir["目录 'images' 的数据块<br>包含更多(文件名, inode号)对"]
        end

        DirEntry1 -->|指向| Inode_File
        DirEntry2 -->|指向| Inode_Dir

        Inode_File -->|指向| DataBlocks_File
        Inode_Dir -->|指向| DataBlocks_Dir
    ```
    *   **工作流程**: 访问文件时，系统首先在目录文件中查找文件名，获得对应的i-node号。然后用此i-node号去i-node区找到具体的i-node，最后通过i-node中的指针访问到真正的数据块。

3.  **计算删除一个文件需要访问磁盘的次数。**

    删除文件所需的磁盘访问次数并非固定，它取决于文件大小、链接数等因素。此处分析一个简化场景：**删除一个链接数为1、且只占用一个数据块的小文件**。

    该过程至少需要以下I/O操作：
    1.  **读父目录的数据块**: 找到文件的目录项，获取其i-node号。（1次读）
    2.  **读文件自身的i-node**: 获取数据块指针，准备释放资源。（1次读）
    3.  **释放数据块**: 将文件占用的数据块归还。这需要修改空闲块管理结构（如位图）。
        *   读空闲块位图。（1次读）
        *   写回修改后的位图。（1次写）
    4.  **释放i-node**: 将i-node归还。这需要修改i-node管理结构。
        *   读i-node位图。（1次读）
        *   写回修改后的位图。（1次写）
    5.  **更新父目录**: 从目录中移除该文件的条目。
        *   写回修改后的父目录数据块。（1次写）

    **总结**: 在此简化模型下，总共大约需要 **3次读** 和 **3次写**，共 **6次磁盘访问**。如果文件很大（包含间接块），则需要额外读取这些间接块，访问次数会更多。

## 五、死锁 (共10分)

1.  给定一个系统状态，判断在执行某个操作后，系统是否仍处于安全状态。

这里给出课上例题作为参考。

5个进程 (P1-P5)，3类资源 (A,B,C)。

|        | 已分配 (Allocation) | 最大需求 (Max) | 尚需要 (Need) |
| :----- | :-----------------: | :------------: | :-----------: |
|        |        A B C        |     A B C      |     A B C     |
| **P1** |        0 1 0        |     7 5 3      |     7 4 3     |
| **P2** |        2 0 0        |     3 2 2      |     1 2 2     |
| **P3** |        3 0 2        |     9 0 2      |     6 0 0     |
| **P4** |        2 1 1        |     2 2 2      |     0 1 1     |
| **P5** |        0 0 2        |     4 3 3      |     4 3 1     |

给定一个系统状态，判断：
1.  此状态是否为安全状态？
2.  P2申请(1,0,2)能否分配？
3.  P5申请(3,3,0)能否分配？
4.  P1申请(0,2,0)能否分配？

**解答**:

**01. 判断当前状态是否安全**

使用安全性算法。`Work = Available = (3,3,2)`。`Finish = {F,F,F,F,F}`。
* **Step 1**: 找一个 `Need[i] <= Work` 的进程。
    * P1? (7,4,3) > (3,3,2) No
    * P2? (1,2,2) <= (3,3,2) Yes. P2可以执行。
    * `Work = Work + Allocation[P2] = (3,3,2) + (2,0,0) = (5,3,2)`. `Finish[P2]=T`.
* **Step 2**:
    * P1? (7,4,3) > (5,3,2) No
    * P3? (6,0,0) > (5,3,2) No
    * P4? (0,1,1) <= (5,3,2) Yes. P4可以执行。
    * `Work = Work + Allocation[P4] = (5,3,2) + (2,1,1) = (7,4,3)`. `Finish[P4]=T`.
* **Step 3**:
    * P1? (7,4,3) <= (7,4,3) Yes. P1可以执行。
    * `Work = Work + Allocation[P1] = (7,4,3) + (0,1,0) = (7,5,3)`. `Finish[P1]=T`.
* **Step 4**:
    * P3? (6,0,0) <= (7,5,3) Yes. P3可以执行。
    * `Work = Work + Allocation[P3] = (7,5,3) + (3,0,2) = (10,5,5)`. `Finish[P3]=T`.
* **Step 5**:
    * P5? (4,3,1) <= (10,5,5) Yes. P5可以执行。
    * `Work = Work + Allocation[P5] = (10,5,5) + (0,0,2) = (10,5,7)`. `Finish[P5]=T`.
    所有进程都可执行完毕，所以 **当前状态是安全的**。一个安全序列是 **<P2, P4, P1, P3, P5>**。

**02. P2申请 (1,0,2)**
* **检查1**: `Request[P2] <= Need[P2]`? (1,0,2) <= (1,2,2) Yes.
* **检查2**: `Request[P2] <= Available`? (1,0,2) <= (3,3,2) Yes.
* **假定分配**:
    * `Available = (3,3,2) - (1,0,2) = (2,3,0)`
    * `Allocation[P2] = (2,0,0) + (1,0,2) = (3,0,2)`
    * `Need[P2] = (1,2,2) - (1,0,2) = (0,2,0)`
* **安全性检查**: 新状态下的 `Work = (2,3,0)`.
    * P2? `Need=(0,2,0) <= (2,3,0)` Yes. `Work = (2,3,0)+(3,0,2) = (5,3,2)`.
    * P4? `Need=(0,1,1) <= (5,3,2)` Yes. `Work = (5,3,2)+(2,1,1) = (7,4,3)`.
    * P1? `Need=(7,4,3) <= (7,4,3)` Yes. `Work = (7,4,3)+(0,1,0) = (7,5,3)`.
    * P3? `Need=(6,0,0) <= (7,5,3)` Yes. `Work = (7,5,3)+(3,0,2) = (10,5,5)`
    * P5? `Need=(4,3,1) <= (10,5,5)` Yes.
    * 系统仍然安全。所以 **可以分配**。

**03. P5申请 (3,3,0)**
* **检查1**: `Request[P5] <= Need[P5]`? (3,3,0) <= (4,3,1) Yes.
* **检查2**: `Request[P5] <= Available`? (3,3,0) <= (3,3,2) Yes.
* **假定分配**:
    * `Available = (3,3,2) - (3,3,0) = (0,0,2)`
    * `Allocation[P5] = (0,0,2) + (3,3,0) = (3,3,2)`
    * `Need[P5] = (4,3,1) - (3,3,0) = (1,0,1)`
* **安全性检查**: 新状态下的 `Work = (0,0,2)`.
    * 此时，没有一个进程的`Need`向量小于等于`Work`向量。系统进入不安全状态。
    * 所以 **不能分配**。

**04. P1申请 (0,2,0)**
* **检查1**: `Request[P1] <= Need[P1]`? (0,2,0) <= (7,4,3) Yes.
* **检查2**: `Request[P1] <= Available`? (0,2,0) <= (3,3,2) Yes.
* **假定分配**:
    * `Available = (3,3,2) - (0,2,0) = (3,1,2)`
    * `Allocation[P1] = (0,1,0) + (0,2,0) = (0,3,0)`
    * `Need[P1] = (7,4,3) - (0,2,0) = (7,2,3)`
* **安全性检查**: 新状态下的 `Work = (3,1,2)`.
    * P1? No. P2? No. P3? No. P4? (0,1,1) <= (3,1,2) Yes.
    * `Work = (3,1,2) + (2,1,1) = (5,2,3)`
    * P2? `Need=(1,2,2) <= (5,2,3)` Yes. `Work = (5,2,3) + (2,0,0) = (7,2,3)`
    * P1? `Need=(7,2,3) <= (7,2,3)` Yes. `Work = (7,2,3) + (0,3,0) = (7,5,3)`
    * P3? `Need=(6,0,0) <= (7,5,3)` Yes. `Work = (7,5,3) + (3,0,2) = (10,5,5)`
    * P5? `Need=(4,3,1) <= (10,5,5)` Yes.
    * 系统仍然安全。所以 **可以分配**。

2.  以哲学家就餐问题为例，简述如何预防死锁。

    哲学家就餐问题的死锁主要源于**循环等待**条件：如果每个哲学家都拿起左手边的筷子，然后等待右手边的筷子，就会形成一个等待环路，所有人都无法进餐。预防死锁的核心就是破坏死锁产生的四个必要条件之一。参考方法如下：

    1.  **破坏"占有并等待"条件**:
        *   **方法**: 要求哲学家必须**同时（原子地）**拿起左右两只筷子，如果不能同时获得，则一只也不拿，并放弃已拿到的筷子。
        *   **实现**: 在"状态数组法"中，`take_forks()`函数通过互斥锁保护，先将哲学家状态设为`HUNGRY`，然后通过`test()`函数检查其左右邻居是否在进食。只有当两只筷子都可用时，才能将状态变为`EATING`并开始进食。这个过程确保了哲学家在无法获得所有必需资源时，不会占有部分资源。

    2.  **破坏"循环等待"条件**:
        *   **方法一：资源排序**。给所有筷子从1到5编号，并要求所有哲学家必须先拿取编号较小的筷子，再拿取编号较大的。例如，哲学家1-4都先拿左筷子再拿右筷子，而哲学家5必须反过来，先拿右筷子(编号1)再拿左筷子(编号5)。这样就打破了环路。
        *   **方法二：限制进入者**。如"限制就餐人数"方案，最多只允许 N-1 (即4个) 哲学家同时尝试拿筷子。这样，在最坏的情况下（4个哲学家每人拿了1只筷子），桌上至少还剩1只空闲的筷子。那么必然有一个哲学家可以拿到两只筷子，吃完后释放资源，从而打破僵局。

## 六、同步问题 (共10分)

1.  **生产者-消费者问题**:
    - 资源总数为 K。
    - 特殊要求：某个消费者(称作`Consumer_B`)必须等待另一个消费者(称作`Consumer_A`)取完5个资源后，才能开始获取资源。
    - 要求使用P、V（信号量）操作解决该同步问题。

    **解答**:
    
    该问题在经典的生产者-消费者模型基础上，增加了两个特定消费者进程间的同步约束。我们可以通过增加一个额外的信号量和一个计数器来实现。

    **1. 信号量和变量定义**

    *   `mutex = 1`: 互斥信号量，用于保护对缓冲区的访问。
    *   `empty = K`: 同步信号量，记录缓冲区中空闲槽位的数量。
    *   `full = 0`: 同步信号量，记录缓冲区中已占用槽位的数量。
    *   `gate_B = 0`: **新增同步信号量**。用于阻塞`Consumer_B`，直到`Consumer_A`完成任务。
    *   `consumed_A_count = 0`: **新增计数器**。用于记录`Consumer_A`消费的资源数量。
    *   `count_mutex = 1`: **新增互斥信号量**。用于保护对`consumed_A_count`的访问。

    **2. 进程伪代码**

    ```c
    // 生产者 (Standard)
    Producer() {
        while(true) {
            produce_item();
            P(empty);
            P(mutex);
            // add item to buffer
            V(mutex);
            V(full);
        }
    }

    // 消费者A (触发者)
    Consumer_A() {
        while(true) {
            P(full);
            P(mutex);
            // remove item from buffer
            V(mutex);
            V(empty);
            consume_item();

            // ---- 特殊逻辑 ----
            P(count_mutex);
            if (consumed_A_count < 5) {
                consumed_A_count++;
                if (consumed_A_count == 5) {
                    V(gate_B); // 当消费满5个时，打开B的门
                }
            }
            V(count_mutex);
        }
    }

    // 消费者B (等待者)
    Consumer_B() {
        // ---- 特殊逻辑 ----
        P(gate_B); // 等待A的信号，此操作只在最开始执行一次

        // ---- 标准消费者逻辑 ----
        while(true) {
            P(full);
            P(mutex);
            // remove item from buffer
            V(mutex);
            V(empty);
            consume_item();
        }
    }
    ```
    *   **工作原理**: `Consumer_B`启动后会立即在`P(gate_B)`处被阻塞。`Consumer_A`每次消费后都会在一个互斥的计数器上加一。当计数器达到5时，`Consumer_A`执行一次`V(gate_B)`，这将唤醒`Consumer_B`。此后，`Consumer_B`将越过`P(gate_B)`的限制，进入其正常的消费循环。
