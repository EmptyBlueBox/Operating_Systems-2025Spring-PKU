# 2019年春季学期操作系统期末考试题目总结

## 1. 简答题

1.  画出进程的虚拟空间的布局。说明 PCB 中是如何体现进程虚拟空间的?
    
    **答：**
    
    1.  **进程的虚拟空间布局 (以Linux为例，从低地址到高地址):**
        ```
            高地址 0xFFFFFFFF  +-----------------------+
                              | 内核地址空间 (Kernel)    | --> 供OS使用，用户模式不可访问
                  0xC0000000  +-----------------------+
                              | 用户栈 (Stack)          | --> 函数调用、局部变量 (向下增长)    |
                              | ----------------------- |
                              |                         |
                              | 内存映射区域            | --> 共享库、内存映射文件             |
                              | (Memory Mapped Region)  |
                              |                         |
                              | ----------------------- |
                              | 堆 (Heap)               | --> 动态内存分配 (malloc) (向上增长) |
                              | ----------------------- |
                              | BSS 段 (Uninit. Data)   | --> 未初始化全局/静态变量            |
                              | ----------------------- |
                              | 数据段 (Data Segment)   | --> 已初始化全局/静态变量            |
                              | ----------------------- |
                              | 代码段 (Text Segment)   | --> 程序指令 (只读)                  |
            低地址  0x00000000 +-----------------------+
        ```

    2.  **PCB 中如何体现进程虚拟空间:**
        *   PCB (进程控制块，在 Linux 中为 `task_struct`) 本身不直接存储地址空间的详细布局，而是作为入口点，间接关联到虚拟空间的完整描述。
        *   PCB 中包含一个指向**内存描述符 (`mm_struct`)** 的指针。
        *   这个 `mm_struct` 结构体才真正描述了进程的整个虚拟地址空间，它内部包含：
            *   **指向页表的指针:** 指明了用于该进程地址转换的页表基地址。
            *   **虚拟内存区域列表 (VMA, `vm_area_struct`):** 一个链表或红黑树，其中每个节点 (VMA) 描述了虚拟地址空间中一段连续的、属性相同的区域 (如代码段、堆、一个映射的文件等)，并定义了其起止地址、访问权限 (读/写/执行) 等。
        *   因此，PCB 通过 `PCB -> mm_struct -> {页表, VMA列表}` 的方式，完整地关联和体现了进程的虚拟空间结构。

2.  "内存映射文件"是什么？与虚拟内存管理有什么联系？

    **答：**

    1.  **"内存映射文件" (Memory-Mapped File) 是什么？**
        *   它是一种I/O机制，允许进程将其虚拟地址空间中的一个区域与一个磁盘文件直接关联(映射)起来。
        *   映射建立后，进程可以像访问普通内存 (如一个数组) 一样，通过指针和内存读写指令来直接访问和修改文件内容，而无需调用 `read()` 或 `write()` 等传统的文件I/O系统调用。

    2.  **与虚拟内存管理有什么联系？**
        *   内存映射文件**完全构建于虚拟内存管理机制之上**，是虚拟内存技术的一个典型且重要的应用。
        *   **共享核心机制：** 它复用了虚拟内存管理的核心组件，包括**虚拟地址空间、页表、和缺页异常处理 (Page Fault)**。
        *   **工作流程体现联系：**
            *   **映射建立：** 调用 `mmap` 时，操作系统仅在进程的虚拟地址空间中预留一段区域 (创建一个VMA)，并修改页表，将这些虚拟页面指向磁盘上的文件作为其**后备存储 (Backing Store)**。这个过程并不发生实际的文件读取。
            *   **按需调页：** 当进程首次访问该内存区域时，会触发**缺页异常**。
            *   **缺页处理：** 虚拟内存系统捕获该异常，从后备存储（即磁盘文件）中加载所需的页面到物理内存，并更新页表，然后恢复进程执行。
        *   **统一管理：** 通过内存映射，文件数据和程序的其他内存数据（如堆、栈）被操作系统以统一的方式（页）进行管理，可以使用统一的页缓存机制来提高I/O效率。

3.  使用"磁盘高速缓存"有什么好处？

    **答：**

    使用"磁盘高速缓存" (Disk Cache / Buffer Cache) 的主要好处是**提升文件系统性能**，其核心在于**减少对物理磁盘的慢速访问次数**。具体好处体现在：

    1.  **加速数据读取：**
        *   磁盘缓存利用了程序的**局部性原理**。当应用请求读取数据时，系统首先检查缓存。如果**命中 (Cache Hit)**，则直接从高速的内存返回数据，避免了耗时的磁盘I/O操作，极大地降低了读延迟。
        *   系统还可以通过**预读 (Read-ahead)** 机制，将可能很快被访问的磁盘块提前读入缓存，提高顺序读性能。

    2.  **加速数据写入：**
        *   采用**延迟写 (Lazy-write)** 策略，应用写入数据时，只需写入内存中的缓存即可立即返回，无需等待数据被写入磁盘。
        *   操作系统可以在后台将这些被修改的缓存页（"脏"页）异步地、分批地写回磁盘。这不仅让写操作对应用来说几乎是瞬时的，还允许操作系统进行I/O调度优化（如合并写操作、排序写请求），提高磁盘整体吞吐率。

    3.  **协调速度差异与资源利用：**
        *   磁盘高速缓存作为内存中的缓冲区，有效**缓解了高速CPU与慢速磁盘之间的速度矛盾**。
        *   现代操作系统通常会将所有未被应用程序使用的空闲物理内存都用作磁盘缓存（形成统一缓存），从而**最大化内存资源的利用率**。

4.  "打开文件"这一操作的意义和流程。

    **答：**

    1.  **"打开文件"操作的意义:**
        *   `open` 操作是在对文件进行读写之前的**预备步骤**。其核心意义在于，将对用户友好的**文件路径名** (如 `/home/user/file.txt`) 转换成一个对内核高效的**文件描述符** (一个小的非负整数)。
        *   它并不是把整个文件加载到内存，而是让内核：
            1.  根据路径找到文件的元数据 (在UNIX中是i-node)。
            2.  检查用户是否有权限访问该文件。
            3.  在内核中创建并初始化管理后续读写会话所需的数据结构。
        *   后续的 `read`, `write` 等操作都将使用这个文件描述符，避免了反复解析路径名和权限检查的开销，提高了效率。

    2.  **"打开文件"的流程 (以UNIX为例):**
        1.  **路径名解析：** 内核接收路径名，从根目录或当前目录开始，逐级搜索目录文件，找到每一级目录/文件名对应的i-node号，最终定位到目标文件的i-node。
        2.  **建立系统级会话：** 内核访问**系统级打开文件表** (System-wide Open File Table)。
            *   如果该文件**已被其他进程打开**，则将对应表项的引用计数加一。
            *   如果该文件**首次被打开**，内核从磁盘读取其i-node信息，在系统级打开文件表中创建一个新表项来存放它，并将引用计数设为1。
        3.  **建立进程级会话：** 内核接着在**当前进程的打开文件表** (Per-process Open File Table) 中创建一个新表项。此表项包含：
            *   一个指向**系统级打开文件表**对应表项的指针。
            *   一个独立的**文件读写指针**，用于记录当前进程对此文件的读写位置。
            *   文件的打开模式（只读、可写等）。
        4.  **返回文件描述符：** 内核将这个新创建的**进程级打开文件表**项的**数组索引**作为文件描述符返回给用户程序。

5.  I/O 管理的主要任务是什么？

    **答：**

    I/O管理是操作系统的核心职能之一，其主要任务是管理和控制各种I/O设备与内存之间的数据传输，并为上层应用提供一个统一、便捷、高效、安全的访问接口。具体任务如下：

    1.  **提供统一的、与设备无关的接口 (设备无关性):**
        *   通过**抽象**（如UNIX的"万物皆文件"）和**封装**（设备驱动程序）来隐藏不同I/O设备的物理细节，为上层应用提供简洁、统一的访问接口（如 `open`, `read`, `write`）。

    2.  **I/O操作的控制与执行:**
        *   **中断处理:** 响应设备的I/O中断，这是感知I/O操作完成、处理错误、启动下一次操作的核心机制。
        *   **设备驱动:** 提供与具体硬件交互的驱动程序，负责发送命令、检查设备状态等。

    3.  **性能优化与效率提升:**
        *   **缓冲与高速缓存 (Buffering/Caching):** 在内存中设置缓冲区，以缓和CPU与慢速I/O设备之间的速度矛盾，并利用局部性原理减少物理I/O次数。
        *   **I/O调度 (Scheduling):** 对I/O请求队列进行排序（如磁盘的电梯调度算法），以优化设备使用效率，提高整体吞吐量。
        *   **SPOOLing技术:** 将独占设备（如打印机）虚拟化为共享设备，提高设备利用率和系统并发能力。

    4.  **设备分配与资源管理:**
        *   为进程分配其所需的I/O设备，解决资源竞争和冲突。
        *   在进程使用完毕后，安全、完整地回收设备。

    5.  **错误处理与保护:**
        *   检测并在I/O过程中发生的错误，并进行相应的处理。
        *   提供保护机制，防止用户进程执行非法的I/O操作。

## 2. 中断/异常/系统调用

1.  如何新加 n 个系统调用？（每个系统调用有 1-3 个参数）

    **答：**

    在类Linux的操作系统中添加一个新的系统调用，通常遵循以下步骤：
    1.  **分配系统调用号：** 在系统调用号的定义文件（如 `unistd.h`）中，为新的系统调用分配一个唯一的编号。
    2.  **添加到系统调用表：** 在内核的系统调用表（`sys_call_table`）中，将新系统调用号与它的内核实现函数（服务例程）的地址关联起来。
    3.  **实现内核服务例程：** 编写一个新的内核函数（通常命名为 `sys_xxx()`），这个函数实现了系统调用的具体功能。函数的参数通过寄存器从用户空间传递进来。
    4.  **重新编译内核：** 修改完成后，需要重新编译整个操作系统内核，才能使新的系统调用生效。

2.  调用 `boo(p1, p2)` 这个新增的系统调用的过程是怎样的？

    **答：**

    调用一个系统调用的过程涉及从用户态到内核态的转换和返回，具体如下：
    1.  **用户态准备：**
        *   应用程序调用库函数 `boo(p1, p2)`。
        *   库函数将 `boo` 对应的**系统调用号**放入指定的寄存器（如 `eax`）。
        *   将参数 `p1`, `p2` 放入其他约定的寄存器中（如 `ebx`, `ecx`）。
        *   执行一条特殊的**陷入指令**（如 `int 0x80` 或 `syscall`），主动触发一个异常，请求进入内核。

    2.  **内核态执行：**
        *   CPU检测到陷入指令，切换到**内核态**，并跳转到预设的异常处理入口（系统调用总入口程序）。
        *   内核保存用户程序的执行现场（寄存器等），然后从 `eax` 寄存器中获取系统调用号。
        *   根据系统调用号，在**系统调用表**中查找到对应的服务例程 `sys_boo` 的地址。
        *   执行 `sys_boo` 函数，它会从 `ebx`, `ecx` 等寄存器中获得参数 `p1`, `p2` 并执行核心逻辑。

    3.  **返回用户态：**
        *   `sys_boo` 执行完毕后，将返回值（如果有）存入 `eax` 寄存器。
        *   内核恢复用户程序的现场。
        *   执行一条特殊的返回指令（如 `iret` 或 `sysret`），CPU切换回**用户态**，回到库函数中。
        *   库函数从 `eax` 中读取返回值，并将其返回给应用程序。

## 3. 虚存设计

1.  对于大小为 2<sup>48</sup> 的虚拟地址空间，如何设计页表？
2.  根据你的设计，说明如何将虚拟地址转换成物理地址。

**答：**

1.  **页表设计 (多级页表):**
    *   对于 2<sup>48</sup> 如此巨大的虚拟地址空间，单级页表会因自身体积过大而不可行。最有效的设计是采用 **多级页表**。
    *   以现代 x86-64 架构为蓝本，可设计一个 **四级页表** 结构。假设页大小为 4KB (2<sup>12</sup> 字节)，则48位虚拟地址可以按 `9-9-9-9-12` 的方式拆分：
        *   **高 36 位 (47-12):** 虚拟页号，用于索引四级页表。
        *   **低 12 位 (11-0):** 页内偏移，用于在最终的物理页框内寻址。
    *   虚拟页号的36位进一步分为4个9位的索引，分别用于查找第一到第四级页表。这种设计的好处是，只有被实际使用的地址空间才需要分配页表内存，极大地节省了空间。

2.  **地址转换流程:**
    *   整个地址转换由硬件 **MMU (内存管理单元)** 自动完成，并由 **TLB (快表)** 加速。
    1.  CPU中的一个特殊寄存器 (如 `CR3`) 存放着顶级页表 (第一级) 的物理基地址。
    2.  MMU 取出虚拟地址的 **第1个9位索引 (bits 47-39)**，用它在第一级页表中找到一个表项(PTE)。这个PTE指向第二级页表的物理基地址。
    3.  MMU 取出 **第2个9位索引 (bits 38-30)**，在第二级页表中找到PTE，指向第三级页表的物理基地址。
    4.  MMU 取出 **第3个9位索引 (bits 29-21)**，在第三级页表中找到PTE，指向第四级页表的物理基地址。
    5.  MMU 取出 **第4个9位索引 (bits 20-12)**，在第四级页表中找到最终的PTE。这个PTE中包含了目标数据所在的 **物理页框号 (PFN)**。
    6.  MMU 将这个 **PFN** 与虚拟地址中原始的 **12位页内偏移 (bits 11-0)** 拼接起来，形成最终的48位物理地址。
    *   **TLB加速:** 在第2步之前，MMU会先在TLB (页表缓存) 中查找该虚拟页。如果命中 (TLB Hit)，则直接得到PFN，跳过2-5步的内存访问，极大提升了效率。如果未命中 (TLB Miss)，才执行完整的页表查询，并将结果存入TLB。
    *   **缺页异常:** 在2-5步的任何一步，如果PTE的有效位为0，表示页面不在内存，MMU会触发 **缺页异常 (Page Fault)**，交由操作系统处理。

## 4. UNIX 文件系统

1.  **UNIX 文件系统的设计中，根目录区前面有哪些部分？**
    *   **答：** 一个典型的UNIX文件卷在"根目录及数据区"之前，主要包含以下几个部分：
        1.  **引导记录 (Boot Block):** 包含引导操作系统所需的信息，位于分区的最开始。
        2.  **超级块 (Superblock):** 存储整个文件系统的元信息，如块大小、i-node总数、空闲块数量等。
        3.  **空闲区管理区:** 用于记录磁盘空闲块状态的数据结构，例如位图或空闲块链表。
        4.  **i-node区 (i-node Area):** 集中存放所有文件的i-node（即文件元数据）的区域。

2.  **如何确定根目录的起始地址？如何设计空闲区管理？**
    *   **答：**
        1.  **确定根目录起始地址:**
            *   根目录本身也是一个文件，它的元数据存储在i-node区的一个i-node中（按惯例，通常是固定的2号i-node）。
            *   确定其地址的流程是：首先访问位于固定位置的**超级块(Superblock)**，从中读取文件系统的布局信息，包括 **i-node区的起始地址**。接着在i-node区中定位到根目录的i-node。此i-node中就包含了指向"根目录内容数据块"的指针，这些指针就是根目录数据存放的起始地址。
        2.  **空闲区管理设计:**
            *   文件系统需要高效地跟踪哪些磁盘块是空闲可用的。两种主要的设计方法：
                *   **位图/位向量 (Bitmap):** 用一个二进制位串来表示所有磁盘块，每一位对应一个块。例如，`1`代表空闲，`0`代表已分配。这种方式查找连续空闲块很高效。
                *   **空闲块链表 (Free Block List):** 将所有空闲的磁盘块通过指针链接成一个或多个链表。超级块中存放指向链表头的指针。

3.  **给出一系列新建文件和文件夹的操作，画出文件系统的布局**

    这里给出课上例题作为参考。

    *   假设一块刚格式化好的磁盘大小为 2MB；每块/簇 大小为 512 字节。
    *   要求画出 (或描述) 在执行下列操作后，一个简化的 UNIX 文件系统和一个 FAT16 文件系统的布局。
    *   操作序列:
        1.  `mkdir /A`
        2.  `mkdir /A/B`
        3.  `create /A/B/File1` (占用 4 块/簇)
        4.  `mkdir /C`
        5.  `mkdir /D`
        6.  `mkdir /C/E`
        7.  `create /C/E/File2` (占用 16 块/簇)
        8.  `mkdir /C/E/F`
        9.  `create /C/E/F/File3` (占用 8 块/簇)
        10. `create /C/E/F/File4` (占用 2 块/簇)

    **解答**:

    UNIX:

    <img src="./2019春-期末-回忆-有答案.assets/UNIX.jpeg" alt="UNIX" style="zoom:50%;" />

    FAT16:

    <img src="./2019春-期末-回忆-有答案.assets/FAT16.jpeg" alt="FAT16" style="zoom:50%;" />

4.  **将某个目录里的某个文件复制到另一个目录下，过程是怎样的？总共要启动硬盘几次？**
    *   **答：**
        **过程:** 将文件A从目录X复制到目录Y下（`cp /X/A /Y/A`），本质上是"读取源文件，创建新文件，写入数据"的过程。其核心I/O步骤如下：
        1.  **解析路径并读取源信息:** 内核需要从根目录开始，逐级读取目录文件的数据块和i-node，先找到目录X，再找到源文件A的i-node，以获取其位置、大小等元信息。至少启动磁盘 2 次: 一次读取目录, 一次读取i-node.
        2.  **解析路径并准备目标位置:** 类似地，从根目录找到目标目录Y的i-node和数据块，并检查权限。同样至少启动磁盘 2 次: 一次读取目录, 一次读取i-node.
        3.  **创建新文件:**
            *   在i-node区为目标文件分配一个**新的i-node**并写入元数据。至少启动磁盘 1 次: 一次写入i-node.
            *   修改**目标目录文件**，添加一个（文件名A，新i-node号）的目录项。至少启动磁盘 1 次: 一次写入目录.
            *   修改**空闲空间管理区**（如位图），标记新i-node和即将使用的数据块为"已占用"。至少启动磁盘 1 次: 一次写入位图.
        4.  **复制数据:** 循环地从源文件A读取数据块，然后写入为新文件分配的数据块，直到文件复制完成。至少启动磁盘 2 次: 一次读取数据块, 一次写入数据块.
        5.  总共启动磁盘 9 次.

## 5. 管程

类似于食品供货问题，用管程解决，说明各个变量和条件变量的含义，关键代码加注释。

二手东卖手机 A 和手机壳 B，仓库里最大数量各为 M 个。二手东将 A、B 搭配出售。有两个供应商不断地向二手东供应 A、B。当仓库里 A 比 B 多 N（$N<M$）个时，二手东暂停 A 的进货。反之，当仓库里 B 比 A 多 N 个时，二手东暂停 B 的进货。

**解答**

**1. 设计思路**

我们将设计一个名为 `PhoneWarehouse` 的管程，它将封装所有共享资源（手机和手机壳的数量）以及对这些资源的操作。管程的特性保证了这些操作（如进货、销售）在同一时间只有一个能被执行，从而天然地解决了互斥问题。

核心的同步问题通过条件变量来解决：

- **进货约束**：
    1.  手机或手机壳的数量不能超过仓库容量 `M`。
    2.  手机A的数量不能比手机壳B的数量多出 `N` 个或以上。
    3.  同样，手机壳B的数量也不能比手机A的数量多出 `N` 个或以上。
- **销售约束**：必须同时有至少一台手机A和一个手机壳B才能进行销售。
当一个进程（供应商或销售员）发现条件不满足时，它将在相应的条件变量上等待。当另一个进程改变了仓库状态后，它会唤醒可能正在等待的进程。

**2. 变量与条件变量**

*   **共享变量**:
    *   `countA (int)`: 仓库中手机A的当前数量。
    *   `countB (int)`: 仓库中手机壳B的当前数量。
*   **常量**:
    *   `M (int)`: 仓库对每种商品的最大容量。
    *   `N (int)`: A与B数量允许的最大差额。
*   **条件变量**:
    *   `canSupplyA`: 当无法进货手机A时（仓库已满或数量差异超限），供应商A在此条件变量上等待。
    *   `canSupplyB`: 当无法进货手机壳B时，供应商B在此条件变量上等待。
    *   `canSell`: 当库存不足以支持一次销售时（缺少A或B），销售员在此条件变量上等待。

**3. 管程伪代码实现**

```c++
// 定义常量
const int M = 100; // 例如，最大容量为100
const int N = 10;  // 例如，最大数量差为10

class PhoneWarehouse {
    int countA = 0;
    int countB = 0;
    condition canSupplyA, canSupplyB, canSell;

    // 供应商A调用此过程进货手机A
    public void SupplyA() {
        // 检查是否满足进货条件
        // 1. 仓库未满
        // 2. 手机A的数量没有比手机壳B多出N个或以上
        while (countA >= M || countA - countB >= N) {
            wait(canSupplyA);
        }

        // 进货，手机A数量加一
        countA++;
        // 进货后，可能会满足销售条件，唤醒销售员
        notify(canSell);
        // 同时，也可能解除了对供应商B的数量限制，唤醒供应商B
        notify(canSupplyB);
    }

    // 供应商B调用此过程进货手机壳B
    public void SupplyB() {
        // 检查是否满足进货条件
        // 1. 仓库未满
        // 2. 手机壳B的数量没有比手机A多出N个或以上
        while (countB >= M || countB - countA >= N) {
            wait(canSupplyB);
        }

        // 进货，手机壳B数量加一
        countB++;
        // 唤醒可能在等待的销售员和供应商A
        notify(canSell);
        notify(canSupplyA);
    }

    // 销售员调用此过程进行销售
    public void Sell() {
        // 检查是否满足销售条件
        // 必须同时有手机A和手机壳B
        while (countA < 1 || countB < 1) {
            wait(canSell);
        }

        // 销售，各减一
        countA--;
        countB--;
        // 销售后，仓库空出位置，且数量差发生变化
        // 这可能使得之前无法进货的供应商可以继续工作，因此将它们全部唤醒
        broadcast(canSupplyA);
        broadcast(canSupplyB);
    }
}

// ---- 外部进程 ----
// 供应商A进程
ProviderA_Process() {
    while(true) {
        PhoneWarehouse.SupplyA();
    }
}

// 供应商B进程
ProviderB_Process() {
    while(true) {
        PhoneWarehouse.SupplyB();
    }
}

// 销售员进程
Seller_Process() {
    while(true) {
        PhoneWarehouse.Sell();
    }
}
```

**注意**：在 `Sell` 过程的结尾，我们使用了 `broadcast` 来唤醒所有等待的供应商。这是因为一次销售会同时改变 `countA` 和 `countB`，可能同时满足供应商A和供应商B的等待条件，使用 `broadcast` 可以确保它们都被唤醒来重新检查条件。在 `Supply` 过程中使用 `notify` 也是可以的，但 `broadcast` 更为稳妥，尤其是在复杂的条件依赖下。在管程编程中，始终使用 `while` 循环来检查等待条件，可以保证被唤醒后逻辑的正确性，即使是被 `broadcast` 意外唤醒。
